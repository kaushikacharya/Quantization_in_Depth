{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3-E - Linear Quantization II: Quantizing Weights & Activations for Inference\n",
    "\n",
    "In this lesson, you will continue to learn different ways of performing linear quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Linear Quantization II` to follow along with the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from helper import linear_q_symmetric, get_q_scale_symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Quantization: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `W8A32` means weights in 8-bits and activations in 32-bits.\n",
    "- For simplicity, the linear layer will be without bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_linear_W8A32_without_bias(input, q_w, s_w, z_w):\n",
    "    assert input.dtype == torch.float32\n",
    "    assert q_w.dtype == torch.int8\n",
    "\n",
    "    dequantized_weight = q_w.to(torch.float32) * s_w + z_w\n",
    "    output = torch.nn.functional.linear(input=input, weight=dequantized_weight)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([1, 2, 3], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([[-2,   -1.13, 0.42],\n",
    "                       [-1.51, 0.25, 1.62],\n",
    "                       [0.23,  1.35, 2.15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_w, s_w = linear_q_symmetric(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-118,  -67,   25],\n",
       "        [ -89,   15,   96],\n",
       "        [  14,   80,  127]], dtype=torch.int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016929134609192376"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = quantized_linear_W8A32_without_bias(input=input, q_w=q_w, s_w=s_w, z_w=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W8A32 output: tensor([-2.9965,  3.8768,  9.3957])\n"
     ]
    }
   ],
   "source": [
    "print(f\"W8A32 output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp32_output = torch.nn.functional.linear(input=input, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output without quantization: tensor([-3.0000,  3.8500,  9.3800])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output without quantization: {fp32_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_quantization_in_depth_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
